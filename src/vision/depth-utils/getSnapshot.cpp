// License: Apache 2.0. See LICENSE file in root directory.
// Copyright(c) 2015 Intel Corporation. All Rights Reserved.

///////////////////////////////////////////////////////
// librealsense tutorial #3 - Point cloud generation //
///////////////////////////////////////////////////////

// This just uses the camera view generated by Intel so that you can take a snapshot of every
// version of the image at this state when you enter a character

#include <getopt.h>
#include <atomic>
#include <chrono>
#include <cstdint>
#include <cstdio>
#include <ctime>
#include <fstream>
#include <iostream>
#include <mutex>
#include <shared_mutex>
#include <sstream>
#include <string>
#include <thread>
#include <vector>

#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"

#include <librealsense/rs.hpp>

#include <pcl/point_cloud.h>
#include <pcl/point_types.h>
#include <cstdio>

#include <pcl/ModelCoefficients.h>
#include <pcl/io/pcd_io.h>

#include "vision/core/getoptSetup.hpp"

#define GLFW_INCLUDE_GLU
#include <GLFW/glfw3.h>

using std::cout;
using std::cerr;
using std::string;
using std::vector;
using cv::Mat;
using std::thread;
using std::atomic;
using cv::imwrite;
using std::mutex;
using std::shared_mutex;
using std::shared_lock;
using std::lock_guard;
using std::unique_lock;

shared_mutex globalMtx;
int snapShotNum{0};
atomic<bool> runSnapshot{false};

void storeDepth(const uint16_t *depthImage)
{
	shared_lock<shared_mutex> lck(globalMtx);
	Mat depthMat(cv::Size(640, 480), CV_16UC1, (void *)depthImage, Mat::AUTO_STEP);
	// Depth image output
	string imgName = "depth";
	imgName += std::to_string(snapShotNum);
	imgName += ".png";
	imwrite(imgName, depthMat);
}

void storeRGB(const uint8_t *rgbImage)
{
	shared_lock<shared_mutex> lck(globalMtx);
	// RGB image output
	Mat color(cv::Size(640, 480), CV_8UC3, (void *)rgbImage, Mat::AUTO_STEP);
	string imgName = "rgb";
	imgName += std::to_string(snapShotNum);
	imgName += ".png";
	imwrite(imgName, color);
}

void storeCombined(const uint8_t *rgbImage, const uint16_t *depthImage)
{
	shared_lock<shared_mutex> lck(globalMtx);
	// Combine the images and store CV8U_C1
	// with dimensions 640 x 1920, to reverse, just use cv::resize()
	Mat color(cv::Size(640, 480), CV_8UC3, (void *)rgbImage, Mat::AUTO_STEP);
	Mat depthMat(cv::Size(640, 480), CV_16UC1, (void *)depthImage, Mat::AUTO_STEP);
	cv::Mat tempDepthMat;
	depthMat.convertTo(tempDepthMat, CV_8UC1);
	cv::Mat splitMats[4];
	cv::split(color, splitMats);
	cv::split(tempDepthMat, splitMats + 3);
	cv::Mat combinedMat;
	cv::merge(splitMats, 4, combinedMat);
	combinedMat.reshape(1, 1920);
	string imgName = "combined";
	imgName += std::to_string(snapShotNum);
	imgName += ".png";
	imwrite(imgName, combinedMat);
}

void takeSnapshot(rs::device *devicePtr)
{
	printf("Taking screenshot: %d\n", ++snapShotNum);
	// Point cloud that hold the points from the depthImage
	pcl::PointCloud<pcl::PointXYZ> cloud;
	pcl::PointCloud<pcl::PointXYZRGBA> cloudXYZRGBA;
	// Writer that writes PCD files
	pcl::PCDWriter pcdwriter;
	// Used to create files for pcl to write to
	std::ofstream foutPcd;
	// Wait for frames
	unique_lock<shared_mutex> lck(globalMtx);  // lock shared mutex
	devicePtr->wait_for_frames();
	// Get frame data
	const uint16_t *depthImage = (const uint16_t *)devicePtr->get_frame_data(rs::stream::depth);
	const uint8_t *colorImage = (const uint8_t *)devicePtr->get_frame_data(rs::stream::color);
	rs::intrinsics depthIntrinsics = devicePtr->get_stream_intrinsics(rs::stream::depth);
	rs::extrinsics depth_to_color = devicePtr->get_extrinsics(rs::stream::depth, rs::stream::color);
	rs::intrinsics color_intrin = devicePtr->get_stream_intrinsics(rs::stream::color);
	lck.unlock();  // unlock shared mutex
	shared_lock<shared_mutex> slck(globalMtx);
	// If specified, store rgb image
	std::vector<std::thread> threads;
	threads.emplace_back(storeRGB, colorImage);
	threads.emplace_back(storeDepth, depthImage);
	threads.emplace_back(storeCombined, colorImage, depthImage);
	float scale = devicePtr->get_depth_scale();
	// Fill the point cloud
	for (int dy{0}; dy < depthIntrinsics.height; ++dy)
	{
		for (int dx{0}; dx < depthIntrinsics.width; ++dx)
		{
			// Retrieve depth value and map it to more "real" coordinates
			uint16_t depthValue = depthImage[dy * depthIntrinsics.width + dx];
			float depthInMeters = depthValue * scale;
			// Skip over values with a depth of zero (not found depth)
			if (depthValue == 0) continue;
			// For mapping color to depth
			// Map from pixel coordinates in the depth image to pixel coordinates in the color image
			rs::float2 depth_pixel = {(float)dx, (float)dy};
			// Projects the depth value into 3-D space
			rs::float3 depthPoint = depthIntrinsics.deproject(depth_pixel, depthInMeters);
			// Creates a corresponding color points in 3-D space (maybe)
			rs::float3 color_point = depth_to_color.transform(depthPoint);
			// Projects the 3-D color point into image space (2-D)
			rs::float2 color_pixel = color_intrin.project(color_point);
			const int cx = (int)std::round(color_pixel.x), cy = (int)std::round(color_pixel.y);
			// int colorIndex = cy * color_intrin.width + cx;
			int colorIndex = (cy * color_intrin.width + cx) * 3;
			// int channelSize = color_intrin.width * color_intrin.height;
			pcl::PointXYZRGBA xyzrgbaPoint;
			if (cy > color_intrin.height || cx > color_intrin.width || cy < 0 || cx < 0)
			{
				xyzrgbaPoint.r = 255;
				xyzrgbaPoint.g = 255;
				xyzrgbaPoint.b = 255;
				xyzrgbaPoint.a = 255;
			}
			else
			{
				xyzrgbaPoint.r = colorImage[colorIndex];
				xyzrgbaPoint.g = colorImage[colorIndex + 1];
				xyzrgbaPoint.b = colorImage[colorIndex + 2];
				xyzrgbaPoint.a = 255;
			}
			xyzrgbaPoint.x = depthPoint.x;
			xyzrgbaPoint.y = depthPoint.y;
			xyzrgbaPoint.z = depthPoint.z;
			cloudXYZRGBA.push_back(xyzrgbaPoint);
			// Push back new point into cloud
			cloud.push_back(pcl::PointXYZ(depthPoint.x, depthPoint.y, depthPoint.z));
		}
	}
	// Store point cloud
	string imgName = "cloud";
	imgName += std::to_string(snapShotNum);
	imgName += ".pcd";
	foutPcd.open(imgName.c_str(), std::ios::out);
	foutPcd.close();
	pcdwriter.writeASCII(imgName, cloud);
	pcl::io::savePCDFileASCII(imgName, cloud);
	// Store other point cloud
	imgName = "RCloud";
	imgName += std::to_string(snapShotNum);
	imgName += ".pcd";
	foutPcd.open(imgName.c_str(), std::ios::out);
	foutPcd.close();
	pcdwriter.writeASCII(imgName, cloudXYZRGBA);
	pcl::io::savePCDFileASCII(imgName, cloudXYZRGBA);
	// Join all created threads back
	while (!threads.empty())
	{
		threads.back().join();
		threads.pop_back();
	}
}

double yaw, pitch, lastX, lastY;
int ml;

static void on_mouse_button(GLFWwindow *win, int button, int action, int mods)
{
	if (button == GLFW_MOUSE_BUTTON_LEFT)
	{
		ml = action == GLFW_PRESS;
		runSnapshot = true;
	}
}

static double clamp(double val, double lo, double hi)
{
	return val < lo ? lo : val > hi ? hi : val;
}

static void on_cursor_pos(GLFWwindow *win, double x, double y)
{
	if (ml)
	{
		yaw = clamp(yaw - (x - lastX), -120, 120);
		pitch = clamp(pitch + (y - lastY), -80, 80);
	}
	lastX = x;
	lastY = y;
}

int main() try
{
	// Turn on logging. We can separately enable logging to console or to file, and use different
	// severity filters for each.
	rs::log_to_console(rs::log_severity::warn);
	// rs::log_to_file(rs::log_severity::debug, "librealsense.log");

	// Create a context object. This object owns the handles to all connected realsense devices.
	rs::context ctx;
	printf("There are %d connected RealSense devices.\n", ctx.get_device_count());
	if (ctx.get_device_count() == 0) return EXIT_FAILURE;

	// This tutorial will access only a single device, but it is trivial to extend to multiple
	// devices
	rs::device *dev = ctx.get_device(0);
	rs::device *&devicePtr = dev;
	printf("\nUsing device 0, an %s\n", dev->get_name());
	printf("    Serial number: %s\n", dev->get_serial());
	printf("    Firmware version: %s\n", dev->get_firmware_version());

	// Configure depth and color to run with the device's preferred settings
	devicePtr->enable_stream(rs::stream::depth, 640, 480, rs::format::z16, 60);
	devicePtr->enable_stream(rs::stream::color, 640, 480, rs::format::bgr8, 60);
	dev->start();

	// Open a GLFW window to display our output
	glfwInit();
	GLFWwindow *win = glfwCreateWindow(1280, 960, "librealsense tutorial #3", nullptr, nullptr);
	glfwSetCursorPosCallback(win, on_cursor_pos);
	glfwSetMouseButtonCallback(win, on_mouse_button);
	glfwMakeContextCurrent(win);
	while (!glfwWindowShouldClose(win))
	{
		// Wait for new frame data
		glfwPollEvents();

		if (runSnapshot)
		{
			runSnapshot = false;
			takeSnapshot(devicePtr);
		}

		dev->wait_for_frames();

		// Retrieve our images
		const uint16_t *depth_image = (const uint16_t *)dev->get_frame_data(rs::stream::depth);
		const uint8_t *color_image = (const uint8_t *)dev->get_frame_data(rs::stream::color);

		// Retrieve camera parameters for mapping between depth and color
		rs::intrinsics depth_intrin = dev->get_stream_intrinsics(rs::stream::depth);
		rs::extrinsics depth_to_color = dev->get_extrinsics(rs::stream::depth, rs::stream::color);
		rs::intrinsics color_intrin = dev->get_stream_intrinsics(rs::stream::color);
		float scale = dev->get_depth_scale();

		// Set up a perspective transform in a space that we can rotate by clicking and dragging the
		// mouse
		glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
		glMatrixMode(GL_PROJECTION);
		glLoadIdentity();
		gluPerspective(60, (float)1280 / 960, 0.01f, 20.0f);
		glMatrixMode(GL_MODELVIEW);
		glLoadIdentity();
		gluLookAt(0, 0, 0, 0, 0, 1, 0, -1, 0);
		glTranslatef(0, 0, +0.5f);
		glRotated(pitch, 1, 0, 0);
		glRotated(yaw, 0, 1, 0);
		glTranslatef(0, 0, -0.5f);

		// We will render our depth data as a set of points in 3D space
		glPointSize(2);
		glEnable(GL_DEPTH_TEST);
		glBegin(GL_POINTS);

		for (int dy = 0; dy < depth_intrin.height; ++dy)
		{
			for (int dx = 0; dx < depth_intrin.width; ++dx)
			{
				// Retrieve the 16-bit depth value and map it into a depth in meters
				uint16_t depth_value = depth_image[dy * depth_intrin.width + dx];
				float depth_in_meters = depth_value * scale;

				// Skip over pixels with a depth value of zero, which is used to indicate no data
				if (depth_value == 0) continue;

				// Map from pixel coordinates in the depth image to pixel coordinates in the color
				// image
				rs::float2 depth_pixel = {(float)dx, (float)dy};
				// Projects the depth value into 3-D space
				rs::float3 depth_point = depth_intrin.deproject(depth_pixel, depth_in_meters);
				// Creates a corresponding color points in 3-D space (maybe)
				rs::float3 color_point = depth_to_color.transform(depth_point);
				// Projects the 3-D color point into image space (2-D)
				rs::float2 color_pixel = color_intrin.project(color_point);

				// Use the color from the nearest color pixel, or pure white if this point falls
				// outside the color image
				const int cx = (int)std::round(color_pixel.x), cy = (int)std::round(color_pixel.y);
				if (cx < 0 || cy < 0 || cx >= color_intrin.width || cy >= color_intrin.height)
				{
					glColor3ub(255, 255, 255);
				}
				else
				{
					glColor3ubv(color_image + (cy * color_intrin.width + cx) * 3);
				}

				// Emit a vertex at the 3D location of this depth pixel
				glVertex3f(depth_point.x, depth_point.y, depth_point.z);
			}
		}
		glEnd();

		glfwSwapBuffers(win);
	}

	return EXIT_SUCCESS;
}
catch (const rs::error &e)
{
	// Method calls against librealsense objects may throw exceptions of type rs::error
	printf("rs::error was thrown when calling %s(%s):\n", e.get_failed_function().c_str(),
		   e.get_failed_args().c_str());
	printf("    %s\n", e.what());
	return EXIT_FAILURE;
}
